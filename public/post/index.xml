<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Abhilash&#39;s Space</title>
    <link>https://abhihash01.github.io/post/</link>
    <description>Recent content in Posts on Abhilash&#39;s Space</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Made with ‚ù§ Abhilash</copyright>
    <lastBuildDate>Sun, 23 Feb 2025 23:54:26 -0500</lastBuildDate><atom:link href="https://abhihash01.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>GPT1</title>
      <link>https://abhihash01.github.io/post/genai/primers/llm/gpt1/</link>
      <pubDate>Sun, 23 Feb 2025 23:54:26 -0500</pubDate>
      
      <guid>https://abhihash01.github.io/post/genai/primers/llm/gpt1/</guid>
      <description>
        
          
            &lt;h1 id=&#34;technical-primer-improving-language-understanding-by-generative-pre-training-gpt-1&#34;&gt;Technical Primer: Improving Language Understanding by Generative Pre-Training (GPT-1)&lt;/h1&gt;
&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;
&lt;p&gt;This work demonstrates the effectiveness of generative pre-training followed by discriminative fine-tuning for natural language understanding tasks. Our approach achieves state-of-the-art results on 9 of 12 benchmarks using a task-agnostic transformer architecture, with absolute improvements up to 8.9% on commonsense reasoning and 5.7% on question answering[1].&lt;/p&gt;
&lt;h2 id=&#34;1-introduction&#34;&gt;1. Introduction&lt;/h2&gt;
&lt;p&gt;Key innovations:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First application of transformer architecture for unsupervised pre-training&lt;/li&gt;
&lt;li&gt;Task-specific input transformations enabling minimal architectural changes&lt;/li&gt;
&lt;li&gt;Demonstration of effective knowledge transfer across diverse NLP tasks&lt;/li&gt;
&lt;li&gt;Analysis of zero-shot learning capabilities in pre-trained models[1]&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;2-framework&#34;&gt;2. Framework&lt;/h2&gt;
&lt;h3 id=&#34;21-unsupervised-pre-training&#34;&gt;2.1 Unsupervised Pre-Training&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;: 12-layer transformer decoder with:&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Bert</title>
      <link>https://abhihash01.github.io/post/genai/primers/llm/bert/</link>
      <pubDate>Tue, 18 Feb 2025 20:54:26 -0500</pubDate>
      
      <guid>https://abhihash01.github.io/post/genai/primers/llm/bert/</guid>
      <description>
        
          
            &lt;h1 id=&#34;bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding&#34;&gt;BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding&lt;/h1&gt;
&lt;h2 id=&#34;core-innovation&#34;&gt;Core Innovation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Deep bidirectional context&lt;/strong&gt; through joint conditioning on left/right context in all layers, overcoming limitations of:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ELMo&#39;s shallow concatenation&lt;/li&gt;
&lt;li&gt;GPT&#39;s unidirectional approach&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;key-architecture-components&#34;&gt;Key Architecture Components&lt;/h2&gt;
&lt;h3 id=&#34;model-specifications&#34;&gt;Model Specifications&lt;/h3&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Parameter&lt;/th&gt;
          &lt;th&gt;BERT-Base&lt;/th&gt;
          &lt;th&gt;BERT-Large&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;Layers&lt;/td&gt;
          &lt;td&gt;12&lt;/td&gt;
          &lt;td&gt;24&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Hidden Dimension&lt;/td&gt;
          &lt;td&gt;768&lt;/td&gt;
          &lt;td&gt;1024&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Attention Heads&lt;/td&gt;
          &lt;td&gt;12&lt;/td&gt;
          &lt;td&gt;16&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;Total Parameters&lt;/td&gt;
          &lt;td&gt;110M&lt;/td&gt;
          &lt;td&gt;340M&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;input-representation&#34;&gt;Input Representation&lt;/h3&gt;
&lt;p&gt;
  &lt;figure&gt;
  &lt;picture&gt;

    
      
        
        
        
        
        
        
    &lt;img
      loading=&#34;lazy&#34;
      decoding=&#34;async&#34;
      alt=&#34;Input Embeddings Diagram&#34;
      
        class=&#34;image_figure image_internal image_processed&#34;
        width=&#34;1258&#34;
        height=&#34;372&#34;
        src=&#34;https://abhihash01.github.io/post/genai/primers/llm/bert/Bert_embedding.png&#34;
      
      
    /&gt;

    &lt;/picture&gt;
&lt;/figure&gt;
&lt;br&gt;
&lt;em&gt;Three embedding types summation&lt;/em&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Token Embeddings&lt;/strong&gt;: WordPiece (30k vocabulary)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Segment Embeddings&lt;/strong&gt;: Sentence A/B differentiation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Position Embeddings&lt;/strong&gt;: Learned positional encoding&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Special tokens:&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Profile</title>
      <link>https://abhihash01.github.io/post/profile/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://abhihash01.github.io/post/profile/</guid>
      <description>
        
          
            &lt;h1 id=&#34;fnu-abhilash&#34;&gt;&lt;strong&gt;FNU ABHILASH&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Data Scientist and Machine Learning Engineer with 3+ years of corporate experience, currently pursuing a Master‚Äôs in Data Science, and specializing in Generative AI, advanced NLP, CV, and recommendation systems.&lt;/p&gt;
&lt;p&gt;üìß &lt;a href=&#34;mailto:abhihash01@gmail.com&#34;&gt;abhihash01@gmail.com&lt;/a&gt;  | üíº (&lt;a href=&#34;https://www.linkedin.com/in/abhilash29998/&#34;&gt;https://www.linkedin.com/in/abhilash29998/&lt;/a&gt;) | üêô (&lt;a href=&#34;https://github.com/abhihash01&#34;&gt;https://github.com/abhihash01&lt;/a&gt;)  | üåê &lt;a href=&#34;https://abhihash01.github.io&#34;&gt;https://abhihash01.github.io&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;skills&#34;&gt;&lt;strong&gt;Skills&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Languages:&lt;/strong&gt; Python, C/C++, Java&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML/DL Tools:&lt;/strong&gt; PyTorch, Keras, Tensorflow, Numpy, Scikit, OpenCV, Pandas, Seaborn, CNN, RNN, LSTM, XGBoost, CatBoost&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concepts:&lt;/strong&gt; Data modeling, Statistical modeling, Regression, Natural Language Processing, Image Processing, Reinforcement Learning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative AI:&lt;/strong&gt; Langchain, LLamaindex, Ollama, Deepspeed, Torchtune, GAN, VAE, Diffusion, PEFT, QLoRA, RAG, Mixture of Experts (MoE), CoT/ Prompt Tuning, SFT, DPO, PPO, LLM Fine Tuning, RAG, CUDA, High Performance Computing, vLLM,OpenAI/Gemini API&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ops:&lt;/strong&gt; Docker, Kafka, Kubernates, Spring Boot, Django, Flask, FastAPI, Selenium, JIRA, Postman, Matlab, R, SAS, A/B Testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data:&lt;/strong&gt; Spark, PySpark, Hadoop, SQL, MySQL, MongoDB, Snowflake, Airflow, MLFlow, AWS, GCP, Sagemaker, Looker, PowerBI&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;experience&#34;&gt;&lt;strong&gt;Experience&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;sap&#34;&gt;SAP&lt;/h3&gt;
&lt;h4 id=&#34;machine-learning-engineer&#34;&gt;&lt;em&gt;Machine Learning Engineer&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;Bangalore, India | Jun 2021 - Aug 2023&lt;/p&gt;
          
          
        
      </description>
    </item>
    
    <item>
      <title>Resume</title>
      <link>https://abhihash01.github.io/post/resume/</link>
      <pubDate>Sat, 09 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://abhihash01.github.io/post/resume/</guid>
      <description>
        
          
            &lt;h1 id=&#34;fnu-abhilash&#34;&gt;&lt;strong&gt;FNU ABHILASH&lt;/strong&gt;&lt;/h1&gt;
&lt;p&gt;Data Scientist and Machine Learning Engineer with 3+ years of corporate experience, currently pursuing a Master‚Äôs in Data Science, and specializing in Generative AI, advanced NLP, CV, and recommendation systems.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;mailto:abhihash01@gmail.com&#34;&gt;abhihash01@gmail.com&lt;/a&gt; |  |&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;skills&#34;&gt;&lt;strong&gt;Skills&lt;/strong&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Languages:&lt;/strong&gt; Python, C/C++, Java&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ML/DL Tools:&lt;/strong&gt; PyTorch, Keras, Tensorflow, Numpy, Scikit, OpenCV, Pandas, Seaborn, CNN, RNN, LSTM, XGBoost, CatBoost&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Concepts:&lt;/strong&gt; Data modeling, Statistical modeling, Regression, Natural Language Processing, Image Processing, Reinforcement Learning&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Generative AI:&lt;/strong&gt; Langchain, LLamaindex, Ollama, Deepspeed, Torchtune, GAN, VAE, Diffusion, PEFT, QLoRA, RAG, Mixture of Experts (MoE), CoT/ Prompt Tuning, SFT, DPO, PPO, LLM Fine Tuning, RAG, CUDA, High Performance Computing, vLLM,OpenAI/Gemini API&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ops:&lt;/strong&gt; Docker, Kafka, Kubernates, Spring Boot, Django, Flask, FastAPI, Selenium, JIRA, Postman, Matlab, R, SAS, A/B Testing&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Data:&lt;/strong&gt; Spark, PySpark, Hadoop, SQL, MySQL, MongoDB, Snowflake, Airflow, MLFlow, AWS, GCP, Sagemaker, Looker, PowerBI&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;experience&#34;&gt;&lt;strong&gt;Experience&lt;/strong&gt;&lt;/h2&gt;
&lt;h3 id=&#34;sap&#34;&gt;SAP&lt;/h3&gt;
&lt;h4 id=&#34;machine-learning-engineer&#34;&gt;&lt;em&gt;Machine Learning Engineer&lt;/em&gt;&lt;/h4&gt;
&lt;p&gt;Bangalore, India | Jun 2021 - Aug 2023&lt;/p&gt;
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
